---
title: Node2vec在推荐系统中的简单应用
typora-root-url: Node2vec在推荐系统中的简单应用
typora-copy-images-to: Node2vec在推荐系统中的简单应用
mathjax: true
tags:
  - 推荐系统
abbrlink: 47603
date: 2020-07-07 00:57:06
---

> 

<!-- more -->



## 1. 背景

之前一段时间组里有其他同事在策略层以提升多样性的手段获取了一些还不错的效果提升，我们排序阶段也尝试着优化系统多样性的方式来提升整体的点击量。但是众所周知，多样性这个指标是很难量化的，一次推荐的结果里类别越多效果越好？还是每个类别「适中」就可以？另外，每个人对多样性的需求上也是有差异的。所以，我们最终在这件事请上还是以「点击量」这个核心指标作为最终效果的评估。通过调整精排模型中结构/输入，让模型根据用户上线问信息决定用户排序结果展现的类别多样性。

对与这个问题，有两个思路：

1）根据用户的隐式负反馈（pv没有click或者其它正向action）来使得模型学习到某个类别在一定时间内已经多次没有正向反馈，先验点击概率较低，所以该类别数据的得分应该降低，其他类别的数据得分应该更高，更多被展现。

2）强化已知正反馈，拓展候选item和更多item的隐式关联关系，使得模型能学到更多数据上的差异，从而来提升多样性效果。

后续的实验都是基于2的假设进行的。

##  2. Node2vec

### 2.1为什么~~（根本不用看的内容）~~

Node2vec综合考虑了DFS和BFS两种邻域的graph embedding方法，简单可以理解为biased random walk 构建node采样序列，通过word2vec的方式学习node embedding，以达到表征网络内结构对等性和同时性。

**模型优化目标**

$$ \mathop{max}\limits_{f} \sum_{u \in V}logPr(N_s(u)|f(u)) $$

设 $f$ 为将定点 $u$ 映射为embedding的映射函数，对于图中每个顶点 $u$ ，定义 $N_s(u)$ 为通过采样策略 $S$ 采样出的顶点 $u$ 的近邻顶点集合。优化的目标是在给定每个顶点条件下，令其近邻顶点出现的概率最大。 

为了让上面的优化问题可以解决，文中提出了两个假设：

**1) 条件独立**

在给定顶点 $u$ 的情况下，其近邻节点出现的概率与其近邻集合中其它顶点无关

$$ Pr(N_s(i) | f(u)) = \mathop{\prod}\limits_{n_i \in {N_s(u)}} Pr(n_i|f(u))  $$  

**2) 特征空间对称**

对于顶点 $u$ 其在作为顶点和近邻点的时候共享同一个 embedding 向量，依此可以将上述条件概率建模为

$$ Pr(n_i|f(u)) = \frac{exp(f(n_i) \cdot f(u))}{\sum_{v \in V} exp(f(v)\cdot f(u))}$$  

 在以上两项假设城里的条件下，优化目标可以被化简为

$$\mathop{max}\limits_{f} \mathop{\sum}\limits_{u \in V} [-logZ_u + \mathop{\sum}\limits_{n_i \in N_s(u)} f(n_i) \cdot f(u)]$$

这里由于$Z_u = \mathop{\sum}\limits_{v \in V} exp(f(u) \cdot f(v)) $ 的计算复杂度太高，所以采用负采样进行优化。

至于 embedding 学习，则是Skip-gram模型去负责了。网络所包含的丰富邻域的信息，则交给顶点采样序列来学习。

**顶点采样策略**

node2vec依然采用随机游走的方式获取顶点的近邻序列，不同的是Node2vec会依照边的权重进一步计算转移概率进行有偏的随机游走。

给定当前节点为$u$ 其访问的下一个节点为$x$ 其概率为

$$ P(c_i =x|c_{i_1}=v)  = 
\begin{cases}
\frac{\pi_{vx}}{z} & if(v,x) \in E \\
0  & otherwise
\end{cases} $$

$\pi_{vx}$ 是顶点 $v$ 和顶点 $x$ 之间未经过归一化的转义概率，$Z$ 是归一化常数。

作者在Random Walks的基础上为每一步Walk引入了偏置 $\alpha$ ，进而通过超参数 $p$ 和 $q$ 来控制随机游走的策略。 如图所示

![](image-20200702213310538-1594054840413.png)

假设当前随机游走经过边 $(t,v)$ 到达顶点 $v$ ，令 $\pi_{vx}=\alpha_{pq}(t,x) \cdot w_{vx}$ , $w_{vx}顶点 $v$ 和 $x$ 之间的权重。

$$ \alpha_{pq}(t,x) = \begin{cases} \frac{1}{p}, & ifd_{tx}=0 \\ 1, & ifd_{tx} = 1\\    \frac{1}{q}, & if d_{tx}=2 \end{cases} $$

其中 $d_{tx}$ 表示顶点 $t$ 和顶点 $x$ 之间的最短距离，且 $d_{tx}$ 的取值范围必须为 $\{0, 1, 2\}$ 其中之一。

参数 $p$ 控制一次游走返回上次顶点的可能性。其并不直接控制游走过程是DFS还是BFS， $p$ 只控制游走的区域是一直接近起点还是逐渐远离起点。

参数 $q$ 控制一次游走向内游走还是向外游走。 其决定了随机游走的方式，结合参数 $q$ ，通过若干次游走采样，能更全面的表征网络信息。

### 2.2 别名采样(alias method)

还没来得及整理，先贴个别人的博客吧（https://zhuanlan.zhihu.com/p/142145549）

## 3. 实际应用

### 3.1 可解释性

> 我们不必要太过纠结文章中提出来的`同质性`和`同构性`，在我个人看来其只是专家们定义出来的一个词语（觉得这两个词更能表达想要表达的意思）
>
> 如果有 A、B、C：AB直接相连，AC也直接相连。用DFS和BFS游走学出来的embedding分别计算相似性：DFS：AB会比较相似，AC也比较相似，BC不一定很接近；BFS：BC会比较相似

**建图**

在我们的自身对于图文信息流进行排序的推荐系统，我最开始选取了文章作为网络结构的顶点，如果两个顶点在同一用户同一Session内同时被曝光且任意一个发生点击，不区分先后顺序（无向图），则将两个顶点相连，记为一次Pv；对于边的权重，如果两个顶点均被点击，则标记为该边被Click，最后用边的Ctr作为边的权重，也就是顶点间的转移概率。针对模型学习到的embedding，预期结果是针对经常在一起出现的节点会比较相似，同时在一起出现，并且点击概率更高的节点会更相似。最终将这些相似性刻画成特征放入到精排模型中，完成对精排模型输入信息量的补充工作。

**关于 `同构性` 和 `同质性` 在这里的理解** 

同质性：文章具有内在的相似性，比如同大类，同一事件，同一实体等具有相似性（用户Session内点击具有话题相关性）

同构性：文章在系统中的相对位置（中心or边缘），比如热点头部数据，比如强时效性数据，比如优质长文/段子（大量头部数据其和众多文章发生关联，但无指向性，或者文章只和少部分关联，一般见于比较小众长文章）

举个例子

```
张文宏：北京疫情只是小范围反弹，中国拒绝第二波疫情
499548adbc674cfe50e790c994c2429f 张文宏：北京疫情只是小范围反弹，中国拒绝第二波疫情 
061e258c0df40cdc8072f6e6b50e8b2c 十三届全国人大常委会第二十次会议表决通过香港特别行政区维护国家安全法 
53357fa1d81ad29672f44e0e69b1e17a 港区国安法表决通过，林郑月娥迅速表态
9d2a3a619f30d0fbc146040b5b982448 香港国安法明确四类罪行和处罚 
f0501259ab91fe631ed2a3d893a08491 香港国安法通过 港澳办、中联办发声 
c1c793d85798d97476963e04240c237a 印度宣布封杀微信抖音等59款中国APP 外交部回应 
85fc6c39f1067145d2d51f69d3d8ac58 香港国安法全文来了：危害国安最高判无期
9155e3c72db07ea5ab0505cfd52317d5 北京：隔离人员中陆续出现多例发生症状不报告的情况 
7bc7475a7b04df19af3ea3f07a945696 31省份新增确诊3例 均在北京
0787fe77b35c9b4d46b19ac462bfa47c 北京昨日新增3例确诊，为19天来最少 
```

针对训练完成的embedding，我们使用一个文章取其相近的10篇文章，其大概包含了三个话题 `北京新冠疫情` `国安法通过` `印度封杀中国app` 因为选取来召回的文章本身就是介绍北京新冠疫情的，所以召回的其他和新冠疫情的文章提现了 `同质性` ；而 `国安法` 和 `印度封杀中国app` 这两个事件同`北京新冠疫情`均属于全局热点时间，被广泛讨论和关注的事件其更符合同构性的逻辑。

**多样性**

讲了一堆，最开始提到我们是要用这个方法来优化系统中数据的多样性问题的，那么多样性究竟提现在哪里了呢？

1）随机采样（$d_{tx} = 2$）带来的高阶多样性

之前精排模块里其实还主要是针对 $d_{tx} = 1$ 的情况行的特征构建与学习。其实对于头部数据而言，其学习效果不用担心，但大量的中长尾顶点，如果其平均近邻节点数为5，在只考虑 $d_{tx} = 1$ 的情况下，其采样序列将会非常局限，虽然采样距离提升会带来噪声和计算复杂度的问题，但在目前看都在可接受和可控制的范围内。

2）在网络中加入user类型的顶点，通过Item----User----item增强多样性。

网络中添加了第二种类型的顶点，User顶点，User顶点的只会和其他Item顶点之间存在直接连接的边，不会与其他User顶点相连。引入User顶点一方面是考虑整个多样性的问题，以一种UserCF的思想扩展稀疏节点的多样性。另外一方面主要是该模型提供的结果需要以特征的方式融合到精排模型中，需要同时考虑到用户侧的信息。

### 3.2 Node和Edge的选取与裁剪

整个图是用以下数据构建的无向图。

| 描述     | 类型 | 权重          | 数量            | 含义                  |
| -------- | ---- | ------------- | --------------- | --------------------- |
| $n_{I}$  | Node | 无            | $5\times10^5$   | 7天内有点击的文章     |
| $n_U$    | Node | 无            | $4\times10^6$   | 7天有点击用户         |
| $e_{ui}$ | Edge | User_ctr      | $1.5\times10^7$ | 用户点击概率          |
| $e_{ii}$ | Edge | Item_pair_ctr | $9\times10^7$   | session内pair点击概率 |

Item和Item之间的边的数量非常大，这里进行了一些才将方面的工作：

1）移除 ${e_{ii}}$ 边数小于5的Item顶点。序列采样过程中是保证每个顶点作为Random Walk的出发点进行K次采样，虽然能保证其至少出现K次，但仍会导致其embedding向量的学习不充分，论文虽提到可以利用邻居的邻居构造样本进行学习，但考虑计算复杂度的问题选择将其舍去。（最开始的时候也抽样选取了部分小于5的顶点上线，统计后验数据来看，该类型的顶点上效果都相对较差。）

2）每个$n_{I}$只保留其 $e_{ii}$ 权重top1000的边。这和我们的系统有关系，我们的系统中，头部数据数据会和大量数据产生关系，所以会有天然的数据倾斜。而这些数据又和其他数据的关联关系上，差异又不是非常大。为了解决计算压力问题，这里针对pair_ctr使用威尔逊区间调整后直接保留top1000

3）每个用户只保留Session内第一个点击的Item构建 $e_{ui}$ 间关系。主要是因为计算压力的问题，因为一个用户可能会有数百条点击历史，整个网络结构会变大很多。如果只保留用户session内的第一次点击的话，整体数量会下降很多，但通过二阶的游走，可以采样得到用户 $e_{ui}$ (用户session内第二次点击)。当用户Session平均长度很小的情况下，在采样中也可以得到对应语料。

4）每个Item只保留权重Top1000的User。一个Item会被若干用户点击，该部分裁剪也只是出于计算压力方面考虑。

## 4. 效果

| ab实验观察项            | 提升   |
| ----------------------- | ------ |
| ctr                     | 2.02%  |
| pv/item                 | 9.79%  |
| item数量                | -8.18% |
| 全部用户人均展现tag数量 | -3.51% |
| 全部用户人均点击tag数量 | 4.03%  |
| 展现用户数              | -0.06% |
| 点击用户数              | 3.27%  |
| 导出                    | 3.56%  |

##  5. 一些有的没的

观察实验结果不难发现，其实这个实验做下来和我们预期正好是相反的。用户展现的Item的tag数量没有得到很好的提升，反而出现了明显的下降。但是点击的tag数量却得到了提升，这不难理解，用户点击率变高了，点击后会有相关的点击反馈影响，所以点击的tag数量自然会提高。

除此之外但还有个明显的问题：展现Item数量明显下降，单个Item展现上涨。这个很好解释。我们的新闻推荐系统，其实是对新数据的需求非常非常大的，单个数据的生命周期也和视频/商品推荐有很大差异。而我们这个模型中暂时还没考虑新加入顶点的问题（天级别计算），同时对稀疏节点进行了采样，这会导致系统更倾向已经有丰富行为的数据。对整个系统来说，算是强化头部及旧数据。

但如果以排序ctr的角度来看，特征的引入缺失能够让（~~短期~~）排序效果更好。

论文中实验对比的DeepWalk和Line的方法在对比方法是是用聚类效果进行评估。但在推荐这种场景下我实在没想明白这个聚类结果和embedding使用的相关性……也就是说离线验证embedding效果其实是很难的事情。同时参数 $p$ 和 $q$ 的调整上我也还没做过多尝试，因为全依照线上ab结果，总的来说实验成本还是有点高。

 都这里，这个实验的第一个版本其实就已经结束了。后续工作的一些思考：

0）新数据的问题。这个暂且不考虑，推荐系统没有银弹，后续工作再去解决   ~~(制造问题，然后再解决问题)~~  ps：这个是否可以用一个的Node2vec的网络只针对冷数据进行训练？

1）采样的时候是否可以引入一些符合主观认知的Side information来控制，防止头部数据集中？

2）$e_{ii}$ 边的权重目前使用用户ctr，但结合 $e_{ii}$  $e_{ui}$ 的权重来看， $e_{ui}$ 的均值要高于 $e_{ii}$，在游走过程中对于当前 $n_{i}$ 顶点，其实是不公平的，这里是否可以将图改造成有向图，将目前 $e_{ii}$ 扩展成双向，但 $e_{ui}$ 只保留目前单向？

3）二阶近邻数量非常高？在推荐系统里有A-B会发生点击；B-C会发生点击；在点击A-B后并不会点C的线上发生，是否在语料规模足够的情况下可以依次来降低二阶近邻的搜索空间？



